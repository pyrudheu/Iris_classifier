{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(shuffle=True): \n",
    "    def irisnames_to_index(iris_name):\n",
    "        if iris_name == b'Iris-setosa': # the b is to indicate that it's a string or something\n",
    "            return 0\n",
    "        elif iris_name == b'Iris-versicolor':\n",
    "            return 1\n",
    "        elif iris_name == b'Iris-virginica':\n",
    "            return 2\n",
    "        else:\n",
    "            print('uh oh.')\n",
    "\n",
    "    def unison_shuffle_data(a,b): # shuffles two 2D arrays, a and b, in unison\n",
    "        assert np.shape(a)[1] == np.shape(b)[1] # since in partice, a and b are X and Y, of shapes (n_x,m) and (n_y,m), we make sure we're looking at the same number of examples\n",
    "        p = np.random.permutation(np.shape(a)[1]) # returns a randomly ordered array of integers leading up to len(a)\n",
    "        return a[:,p],b[:,p] # return two arrays, shuffled based on the order of the randomly permuted integers of p\n",
    "            \n",
    "    with open('iris.data','r') as f:\n",
    "        XY = np.loadtxt(f,delimiter=',',converters={-1:irisnames_to_index}) # the converters dictionary converts entries in the last column by calling irisnames_to_index !\n",
    "        X_tot = XY[:,: 4].T  # X is a matrix of shape (n_x,m)\n",
    "        Ytemp = XY[:,4 :].T  # Ytemp is a matrix of shape (1,m). dim0 is a number (0, 1, or 2). Let's convert that to a one-hot vector\n",
    "        m_tot = np.shape(Ytemp)[1]\n",
    "        Y_tot = np.eye(3)[Ytemp[0].astype(int)].T # now we have Y, a matrix of shape (n_y,m)! dim0 is a one-hot array, indicating the plant type!\n",
    "        if shuffle:\n",
    "            X_tot,Y_tot = unison_shuffle_data(X_tot,Y_tot)\n",
    "        return X_tot,Y_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tot,Y_tot = load_dataset() # we pull up all the X and Y data we have. Note that is is unshuffled.\n",
    "m_tot = np.shape(X_tot)[1]\n",
    "X_train = X_tot[:, : 100] # we take the first 100 examples of X_tot as training data\n",
    "X_test = X_tot[:,100 :] # we take the last 50 examples of X_tot as test data\n",
    "Y_train = Y_tot[:,: 100] # same idea with Y labels\n",
    "Y_test = Y_tot[:,100 :]\n",
    "assert np.shape(X_train)[1] == np.shape(Y_train)[1]\n",
    "m_train = np.shape(X_train)[1]\n",
    "m_test = np.shape(Y_train)[1]\n",
    "\n",
    "# Now, we have 100 examples of training data (X_train,Y_train) and 50 examples of test data (X_test,Y_test)! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(n_x,n_y): # this is where we decide the NN architecture. Let's take n_x as an argument, since our first layer weights need to deal with that. Same idea with n_y\n",
    "    parameters = {'W1':None,'b1':None,'W2':None,'b2':None,'W3':None,'b3':None}\n",
    "    # randomly initializing parameters to be in Gaussian distribution, with mean 0 and variance 1\n",
    "    parameters['W1'] = np.random.randn(5,n_x)*np.sqrt(2/(n_x)) # actually initializing w He initialization\n",
    "    parameters['b1'] = np.random.randn(5,1)*np.sqrt(2/(n_x))\n",
    "    parameters['W2'] = np.random.randn(6,5)*np.sqrt(2/(5))\n",
    "    parameters['b2'] = np.random.randn(6,1)*np.sqrt(2/(5))\n",
    "    parameters['W3'] = np.random.randn(n_y,6)*np.sqrt(2/(6))\n",
    "    parameters['b3'] = np.random.randn(n_y,1)*np.sqrt(2/(6))\n",
    "    return parameters\n",
    "\n",
    "def initialize_gradients(parameters):\n",
    "    gradients={\n",
    "        'dW1':None,\n",
    "        'db1':None,\n",
    "        'dW2':None,\n",
    "        'db2':None,\n",
    "        'dW3':None,\n",
    "        'db3':None\n",
    "    }\n",
    "    gradients['dW1'] = np.zeros(np.shape(parameters['W1']))\n",
    "    gradients['db1'] = np.zeros(np.shape(parameters['b1']))\n",
    "    gradients['dW2'] = np.zeros(np.shape(parameters['W2']))\n",
    "    gradients['db2'] = np.zeros(np.shape(parameters['b2']))\n",
    "    gradients['dW3'] = np.zeros(np.shape(parameters['W3']))\n",
    "    gradients['db3'] = np.zeros(np.shape(parameters['b3']))\n",
    "    return gradients\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(ZL): # inputs the vector Z of the final layer\n",
    "    denom = np.sum((np.exp(ZL-np.max(ZL))),axis=0) # subtract max(x) to shrink values & avoid exploding gradient\n",
    "    return np.divide((np.exp(ZL-np.max(ZL))),denom)\n",
    "def sigmoid(ZL): # NOTE: decided to go w relu on all just bc it's easier to do derivatives\n",
    "    return 1/(1+np.exp(-ZL))\n",
    "def relu(ZL):\n",
    "    return ZL.clip(min=0) # clips all negative elements of ZL, setting them to 0\n",
    "def relu_back(AL): # computes derivative of relu fn, given the layer's activation\n",
    "    mask = np.zeros(np.shape(AL))\n",
    "    mask[AL>0]=1 # NOTE: technically, should be 1 or 0 based on ZL, not AL. But since AL = 0 iff ZL <= 0, this still works as shorthand\n",
    "    mask[AL<=0]=0\n",
    "#     print('AL is: ' +str(AL))\n",
    "#     print('mask is: '+str(mask))\n",
    "    return mask # return original value of AL if entry was nonnegative; 0 if negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(X,Y,parameters,lambd=0): # given a set of parameters and our data, let's pass it forward and see what our guesses are.\n",
    "    m = np.shape(X)[1]\n",
    "    \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    \n",
    "    Z1 = np.dot(W1,X)+b1\n",
    "    A1 = relu(Z1)\n",
    "    \n",
    "    Z2 = np.dot(W2,A1)+b2\n",
    "    A2 = relu(Z2)\n",
    "\n",
    "    Z3 = np.dot(W3,A2)+b3\n",
    "    A3 = softmax(Z3)\n",
    "\n",
    "    assert np.shape(A3) == np.shape(Y)\n",
    "\n",
    "    cost = 1/m*(np.sum(np.multiply(Y,-np.log(A3))) + 0.5*lambd*(np.sum(W3**2)+np.sum(W2**2)+np.sum(W1**2)))# let's do the cross entropy loss\n",
    "\n",
    "    cache = (Z1,Z2,Z3,X,A1,A2,lambd) # saving these babies for later\n",
    "    \n",
    "    return A3,cache,cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_prop(A3,Y,cache, parameters,gradients,debug=False):    # Note: A3, Y, and cache can be of however many examples we happen to want to input at once\n",
    "    (Z1,Z2,Z3,X,A1,A2,lambd) = cache\n",
    "    m = np.shape(X)[1]\n",
    "    \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    \n",
    "\n",
    "    dZ3 = A3-Y # someone calculated this here: https://deepnotes.io/softmax-crossentropy\n",
    "    dW3 = 1/m*(np.dot(dZ3,A2.T) + lambd*np.sum(abs(W3)))\n",
    "    db3 = 1/m*np.sum(dZ3,axis=1,keepdims=True) # so we don't get any rank 1 arrays\n",
    "\n",
    "    if debug:\n",
    "        print('Layer 3 Backprop:')\n",
    "#         print('dA3 = '+str(np.average(dA3)))\n",
    "        print('dZ3 = '+str(np.average(dZ3)))\n",
    "        print('dW3 = '+str(np.average(dW3)))\n",
    "        print('db3 = '+str(np.average(db3)))\n",
    "        print('~'*30)\n",
    "    \n",
    "    dA2 = np.dot(W3.T,dZ3) # basically running fwd prop but in reverse! using W3.T to get from dZ3 to A2, instead of the other way around! :D\n",
    "    dZ2 = np.multiply(dA2,relu_back(A2)) # derivative of the relu fn\n",
    "    dW2 = 1/m*(np.dot(dZ2,A1.T) + lambd*np.sum(abs(W2)))# include regulaization term\n",
    "    db2 = 1/m*np.sum(dZ2,axis=1,keepdims=True)\n",
    "    \n",
    "    if debug:\n",
    "        print('Layer 2 Backprop:')\n",
    "#         print('dA2 = '+str(np.average(dA2)))\n",
    "        print('dZ2 = '+str(np.average(dZ2)))\n",
    "        print('dW2 = '+str(np.average(dW2)))\n",
    "        print('db2 = '+str(np.average(db2)))\n",
    "        print('~'*30)\n",
    "    \n",
    "    dA1 = np.dot(W2.T,dZ2)\n",
    "    dZ1 = np.multiply(dA1,relu_back(A1))\n",
    "    dW1 = 1/m*(np.dot(dZ1,X.T) + lambd*np.sum(abs(W1)))\n",
    "    db1 = 1/m*np.sum(dZ1,axis=1,keepdims=True)\n",
    "    \n",
    "    if debug:\n",
    "        print('Layer 1 Backprop:')\n",
    "#         print('dA1 = '+str(np.average(dA1)))\n",
    "        print('dZ1 = '+str(np.average(dZ1)))\n",
    "        print('dW1 = '+str(np.average(dW1)))\n",
    "        print('db1 = '+str(np.average(db1)))\n",
    "        print('~'*30)\n",
    "    \n",
    "    assert (np.shape(W1)==np.shape(dW1))\n",
    "    assert (np.shape(b1)==np.shape(db1))\n",
    "    assert (np.shape(W2)==np.shape(dW2))\n",
    "    assert (np.shape(b2)==np.shape(db2))\n",
    "    assert (np.shape(W3)==np.shape(dW3))\n",
    "    assert (np.shape(b3)==np.shape(db3))\n",
    "    \n",
    "    \n",
    "    gradients['dW1'] = dW1\n",
    "    gradients['db1'] = db1\n",
    "    gradients['dW2'] = dW2\n",
    "    gradients['db2'] = db2\n",
    "    gradients['dW3'] = dW3\n",
    "    gradients['db3'] = db3\n",
    "    \n",
    "    \n",
    "    return gradients\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters,gradients,learning_rate=0.005,clip=False):\n",
    "    if clip:\n",
    "        parameters['W1'] = parameters['W1'] - learning_rate*np.clip(gradients['dW1'],-5,5)\n",
    "        parameters['b1'] = parameters['b1'] - learning_rate*np.clip(gradients['db1'],-5,5)\n",
    "        parameters['W2'] = parameters['W2'] - learning_rate*np.clip(gradients['dW2'],-5,5)\n",
    "        parameters['b2'] = parameters['b2'] - learning_rate*np.clip(gradients['db2'],-5,5)\n",
    "        parameters['W3'] = parameters['W3'] - learning_rate*np.clip(gradients['dW3'],-5,5)\n",
    "        parameters['b3'] = parameters['b3'] - learning_rate*np.clip(gradients['db3'],-5,5)  \n",
    "    else:\n",
    "        parameters['W1'] = parameters['W1'] - learning_rate*gradients['dW1']\n",
    "        parameters['b1'] = parameters['b1'] - learning_rate*gradients['db1']\n",
    "        parameters['W2'] = parameters['W2'] - learning_rate*gradients['dW2']\n",
    "        parameters['b2'] = parameters['b2'] - learning_rate*gradients['db2']\n",
    "        parameters['W3'] = parameters['W3'] - learning_rate*gradients['dW3']\n",
    "        parameters['b3'] = parameters['b3'] - learning_rate*gradients['db3']\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cost(costs,validation_costs=None):\n",
    "    plt.plot(costs)\n",
    "    plt.ylabel('Cost')\n",
    "    plt.xlabel('Iterations')\n",
    "    if validation_costs!=None:\n",
    "        plt.plot(validation_costs)\n",
    "        plt.legend(('Training Error','Validation Error'))\n",
    "    else:\n",
    "        plt.legend(('Training Error'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_model(X,Y,\n",
    "                X_test=None,\n",
    "                Y_test=None,\n",
    "                epochs=10,\n",
    "          show_epochs=True,\n",
    "          lambd=0.5,\n",
    "          starting_parameters=None,\n",
    "          clip_grads=False,\n",
    "          debug_backprop=False,\n",
    "          plot_costs=True,\n",
    "          learning_rate=0.005\n",
    "         ):\n",
    "    \n",
    "    n_x = np.shape(X)[0]\n",
    "    n_y = np.shape(Y)[0]\n",
    "    \n",
    "    if starting_parameters == None:\n",
    "        parameters = initialize_parameters(n_x,n_y)\n",
    "    else:\n",
    "        parameters = starting_parameters\n",
    "#     print('initial param = '+str(parameters['W3'][1,1]))\n",
    "    gradients = initialize_gradients(parameters)\n",
    "    \n",
    "    costs=[]\n",
    "    \n",
    "    validation_costs=[]\n",
    "    \n",
    "    for ep in range(epochs):\n",
    "        A3,cache,cost = forward_prop(X,Y,parameters,lambd=lambd)\n",
    "        if X_test.all()!=None and Y_test.all()!=None:\n",
    "            _,_,val_cost = forward_prop(X_test,Y_test,parameters,lambd=lambd)\n",
    "            validation_costs.append(val_cost)\n",
    "        gradients = back_prop(A3,Y,cache,parameters,gradients,debug=debug_backprop)\n",
    "        parameters = update_parameters(parameters,gradients,clip=clip_grads,learning_rate=learning_rate)\n",
    "        costs.append(cost)\n",
    "        \n",
    "        if show_epochs:\n",
    "            print('Epoch '+str(ep) +':')\n",
    "            print('cost = '+str(cost))\n",
    "#             if clip_grads:\n",
    "#                 print('grad = ' +str(np.clip(np.average(gradients['dW3']),-5,5)))\n",
    "#             else:\n",
    "#                 print('grad = ' +str(np.average(gradients['dW3'])))\n",
    "#             print('param = '+str(np.average(parameters['W3'])))\n",
    "            print('>'*50)\n",
    "\n",
    "    if plot_costs:\n",
    "        if X_test.all()!=None and Y_test.all()!=None:\n",
    "            plot_cost(costs,validation_costs=validation_costs)\n",
    "        else:\n",
    "            plot_cost(costs)\n",
    "            \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X,Y,parameters):\n",
    "#     print(np.shape(X))\n",
    "    A3,_,cost = forward_prop(X,Y,parameters,lambd=0) # we only care about our predictions, A3!\n",
    "    indices = np.argmax(A3,axis=0) # returns index of greatest value in a particular prediction (column) of A3\n",
    "    pred = np.eye(3)[indices].T # converts indices to a one-hot vector! amazing!\n",
    "    \n",
    "    total_guesses = np.shape(X)[1]\n",
    "    correct_guesses = np.sum(np.multiply(Y,pred)) # since Y and pred are both one-hot vectors, we can do elementwise multiplication. This will return 1 for matching columns, and 0 for non-matching ones. Summing these up will yield the number of correct guesses.\n",
    "    \n",
    "    accuracy = correct_guesses/total_guesses\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "def single_predict(X,parameters,Y=np.zeros((3,1)),answer=None):\n",
    "    X = np.asarray(X)\n",
    "    Y = np.asarray(Y)\n",
    "    X = X.reshape(-1,1) # makes X and Y into column vectors\n",
    "    Y = Y.reshape(-1,1)\n",
    "    A3,_,cost = forward_prop(X,Y,parameters,lambd=0)\n",
    "    index = np.argmax(A3,axis=0) # returns index of greatest value in a particular prediction (column) of A3\n",
    "    print('The Neural Network says: ')\n",
    "    if index==0:\n",
    "        print('Hmmm... I think this is an Iris-setosa.')\n",
    "    elif index==1:\n",
    "        print('Why of course! This must be an Iris-versicolor!')\n",
    "    elif index==2:\n",
    "        print('This is none other than an Iris-virginica.')\n",
    "    else:\n",
    "        print('Something went wrong...')\n",
    "    print(\"* \"*10)\n",
    "    if Y.all()!=None and answer==None:\n",
    "        if np.sum(Y*np.eye(3)[0].reshape(-1,1))==1:\n",
    "            print('The correct answer is Iris-setosa.')\n",
    "        elif np.sum(Y*np.eye(3)[1].reshape(-1,1))==1:\n",
    "            print('The correct answer is Iris-versicolor.')\n",
    "        elif np.sum(Y*np.eye(3)[2].reshape(-1,1))==1:\n",
    "            print('The correct answer is Iris-virginica.')\n",
    "    elif Y.all()==None and answer!=None:\n",
    "        print('The correct answer is '+str(answer))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.98\n",
      "Accuracy on test data: 0.96\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "The Neural Network says: \n",
      "Why of course! This must be an Iris-versicolor!\n",
      "* * * * * * * * * * \n",
      "The correct answer is Iris-versicolor.\n"
     ]
    }
   ],
   "source": [
    "# Now, let's put it all together!\n",
    "\n",
    "parameters = train_model(\n",
    "                    X_train[:,:],\n",
    "                    Y_train[:,:],\n",
    "                    X_test,\n",
    "                    Y_test,\n",
    "                    epochs=5000,\n",
    "                    show_epochs=False,\n",
    "                    clip_grads=False,\n",
    "                    debug_backprop=False,\n",
    "                    learning_rate = 0.001,\n",
    "                  )\n",
    "print(\"Accuracy on training data: \" + str(predict(X_test[:,:],Y_test[:,:],parameters)))\n",
    "print(\"Accuracy on test data: \" + str(predict(X_train[:,:],Y_train[:,:],parameters)))\n",
    "\n",
    "print('~'*50)\n",
    "\n",
    "# single_predict(\n",
    "#     [7.7,3.0,6.1,2.3],\n",
    "#     parameters,\n",
    "#     Y=[0,0,1]\n",
    "# )\n",
    "single_predict(\n",
    "    X_test[:,5],\n",
    "    parameters,\n",
    "    Y=Y_test[:,5]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single_predict(\n",
    "#     X_test[:,2],\n",
    "#     parameters,\n",
    "#     Y=Y_test[:,2]\n",
    "# )\n",
    "\n",
    "def guess(example_num):\n",
    "    single_predict(X_test[:,example_num],parameters,Y=Y_test[:,example_num])\n",
    "    \n",
    "    \n",
    "for i in range(10):\n",
    "    guess(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single_predict(\n",
    "#     X_test[:,9],\n",
    "#     parameters,\n",
    "#     Y=Y_test[:,9]\n",
    "# )\n",
    "\n",
    "def interactive_guess(parameters):\n",
    "    X = np.zeros((4,1))\n",
    "    sepal_length = input('Sepal length (cm): ')\n",
    "    try:\n",
    "        sepal_length = float(sepal_length)\n",
    "    except:\n",
    "        print('Please enter a number!')\n",
    "        return\n",
    "    sepal_width = input('Sepal width (cm): ')\n",
    "    try:\n",
    "        sepal_width = float(sepal_width)\n",
    "    except:\n",
    "        print('Please enter a number!')\n",
    "        return\n",
    "    petal_length = input('Petal length (cm): ')\n",
    "    try:\n",
    "        petal_length = float(petal_length)\n",
    "    except:\n",
    "        print('Please enter a number!')\n",
    "        return\n",
    "    petal_width = input('Petal width (cm): ')\n",
    "    try:\n",
    "        petal_width = float(petal_width)\n",
    "    except:\n",
    "        print('Please enter a number!')\n",
    "        return\n",
    "    \n",
    "    X[0][0]=sepal_length\n",
    "    X[1][0]=sepal_width\n",
    "    X[2][0]=petal_length\n",
    "    X[3][0]=petal_width\n",
    "    \n",
    "    print(X)\n",
    "    \n",
    "    single_predict(X,parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    877\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    879\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    466\u001b[0m         \"\"\"\n\u001b[0;32m--> 467\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-d6c3a1430eed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minteractive_guess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-cba7d33514f8>\u001b[0m in \u001b[0;36minteractive_guess\u001b[0;34m(parameters)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minteractive_guess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0msepal_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Sepal length (cm): '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0msepal_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msepal_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    851\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    854\u001b[0m         )\n\u001b[1;32m    855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    881\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 883\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    884\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "interactive_guess(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
